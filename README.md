# ğŸ›°ï¸ AI-Driven Real-Time Drone Detection and Monitoring via Web Interface

This project is a Flask-based web application designed to detect drones in uploaded videos, images, and live webcam streams using custom-trained YOLOv11 models. Users can upload footage or access the real-time detection mode, after which the app automatically extracts frames, performs drone detection, and visually annotates the results through a responsive dashboard interface.

---

## ğŸš€ Features

The system includes the following main features:

* ğŸ“¤ Upload support for both video (`.mp4`, `.avi`) and image (`.jpg`, `.png`) files
* ğŸï¸ Frame-by-frame extraction using ImageIO or OpenCV
* ğŸ¯ Drone detection using custom-trained YOLOv11m (for uploads) and YOLOv11n (for live webcam)
* ğŸ–¼ï¸ Annotated frames with bounding boxes and confidence scores
* ğŸ“Š Detection summaries for frame-level analysis
* ğŸ” Click-to-zoom modal previews for inspection of frames
* ğŸ–¥ï¸ Clean, responsive, dark-themed UI dashboard

---

## ğŸ› ï¸ Tech Stack

**ğŸ”§ Backend Technologies:**

* ğŸ§ª Flask â€“ API routing and detection backend
* ğŸ¤– YOLOv11 (Ultralytics) â€“ custom-trained drone detection models
* ğŸ”¥ PyTorch â€“ for YOLO model inference
* ğŸ‘ï¸ OpenCV â€“ used for webcam input and optional frame extraction
* ğŸ Python Libraries â€“ `imageio`, `Pillow`, `os`, `uuid`, `shutil`, etc.

**ğŸ¨ Frontend Technologies:**

* ğŸ§± HTML5 + CSS3 â€“ layout and modern dark UI
* âš¡ JavaScript â€“ Fetch API for asynchronous data loading and preview updates

---

## ğŸ“ Project Structure
```
<pre>
â”œâ”€â”€ app.py                       # Flask backend server
â”œâ”€â”€ detector.py                  # YOLOv11 object detection logic
â”œâ”€â”€ render.yaml                  # Script to deploy on Render
â”œâ”€â”€ requirements.txt             # Required Python dependencies
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ Nano_Model/
â”‚       â”œâ”€â”€ 1_nano.pt            # Base YOLOv11n model (from Ultralytics)
â”‚       â”œâ”€â”€ 2_nano.pt            # Base YOLOv11n model (from Ultralytics - Better)
â”‚   â”œâ”€â”€ 1_best.pt                 # Custom-trained YOLOv11m model (final version) 
â”‚   â”œâ”€â”€ 2_best.pt                # Custom-trained YOLOv11m model (final version - Better) 
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ annotated_frames/        # YOLO-annotated output images
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Dashboard styling
â”‚   â”œâ”€â”€ frames/                  # Extracted frames from uploaded media
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ script.js            # Frontend logic (media display, zoom, etc.)
â”‚   â””â”€â”€ uploads/                 # Uploaded raw media files
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html               # Main dashboard layout (HTML template)
</pre>
```

---

## âš™ï¸ Setup Instructions

1. ğŸ§© Clone the repository:  
   `git clone https://github.com/your-username/drone-vision-system.git`

2. ğŸ“ Navigate to the folder:  
   `cd drone-vision-system`

3. ğŸ“¦ Install dependencies:  
   `pip install -r requirements.txt`

4. ğŸ› ï¸ Run the Flask app:  
   `python app.py`

5. ğŸŒ Open your browser:  
   Visit `http://127.0.0.1:5000`
#The server currently runs on local host only.
---

## ğŸ“¸ Live-Webcam Detection Mode (Not yet implemented)

To run real-time webcam-based detection using the YOLOv11n model:
- Launch the webcam script (if separate), or
- Select â€œLive Detectionâ€ from the interface if enabled.
  
> ğŸ”§ **Planned Feature:**
- Real-time drone detection using live webcam input (to be added in future versions).
- Planned deployment on platforms like Render or Replit to enable public access and real-time online testing.

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the `LICENSE` file for full details.

